# Status Update for ChatGPT: Dataset Ingestion Pipeline

## ‚úÖ What Cursor Has Already Implemented

**File: `amprenta_rag/ingestion/dataset_ingestion.py`**

### 1. Metadata Extraction (‚âà80% Complete)
- ‚úÖ `_extract_mwtab_from_page_content()` - Extracts mwTab JSON from Notion page content (code blocks under "mwTab Data" heading)
- ‚úÖ `_extract_metadata_from_mwtab()` - Parses mwTab JSON and extracts:
  - ‚úÖ `model_systems` (from SUBJECT.SUBJECT_SPECIES)
  - ‚úÖ `disease_terms` (pattern matching from STUDY_TITLE/STUDY_SUMMARY)
  - ‚úÖ `matrix_terms` (from SUBJECT.SUBJECT_TYPE)
  - ‚úÖ `methods` (from TREATMENT, SAMPLEPREP, CHROMATOGRAPHY sections)
  - ‚úÖ `summary` (from STUDY.STUDY_SUMMARY)
  - ‚úÖ `results` (basic metabolite count info)
  - ‚ùå `conclusions` - NOT YET IMPLEMENTED
  - ‚ùå `data_origin` - NOT YET IMPLEMENTED
  - ‚ùå `dataset_source_type` - NOT YET IMPLEMENTED
  - ‚ùå `source_url` - NOT YET IMPLEMENTED

### 2. Notion Update Helper (‚âà70% Complete)
- ‚úÖ `_update_experimental_data_asset_metadata()` - Updates Notion page with metadata
- ‚úÖ Updates: Model Systems, Disease, Matrix (all as multi_select)
- ‚úÖ Updates: Methods, Summary, Results (all as rich_text - matches schema)
- ‚ùå `Conclusions` - NOT YET IMPLEMENTED
- ‚ùå `Data Origin` (select) - NOT YET IMPLEMENTED
- ‚ùå `Dataset Source Type` (select) - NOT YET IMPLEMENTED
- ‚ùå `Source URL / DOI` (url) - NOT YET IMPLEMENTED
- ‚ùå `Full Text (hidden)` - NOT YET IMPLEMENTED (optional)
- ‚ùå `Chunks (hidden)` - NOT YET IMPLEMENTED (optional)

### 3. Integration (‚úÖ Complete)
- ‚úÖ Wired into `ingest_dataset()` flow
- ‚úÖ Runs after successful Pinecone upsert
- ‚úÖ Runs after Embedding IDs + Last Embedded update
- ‚úÖ Error handling: Metadata failures logged as warnings, don't fail ingestion

### 4. Backfill Script (‚úÖ Complete)
- ‚úÖ `scripts/backfill_dataset_metadata.py` exists and works
- ‚úÖ Finds pages missing metadata
- ‚úÖ Processes pages with mwTab data

---

## üìã What's Still Needed (Per ChatGPT's Instructions)

### Missing Fields in Metadata Extraction:
1. `conclusions` - Needs LLM generation or extraction from mwTab
2. `data_origin` - Should infer from source (e.g., "External ‚Äì Open Dataset" for Metabolomics Workbench)
3. `dataset_source_type` - Should infer from mwTab structure (e.g., "Processed table" for ST004396)
4. `source_url` - Extract from mwTab or pass as parameter

### Missing Fields in Notion Update:
1. `Conclusions` (rich_text)
2. `Data Origin` (select) - Values: "Internal ‚Äì Amprenta", "External ‚Äì Published", "External ‚Äì CRO/Vendor", "External ‚Äì Open Dataset", "Collaboration"
3. `Dataset Source Type` (select) - Values: "Raw file", "Processed table", "Summary (stats only)", "DOI / link only", "Supplemental table"
4. `Source URL / DOI` (url)
5. `Full Text (hidden)` (rich_text) - Optional: store full mwTab text
6. `Chunks (hidden)` (rich_text) - Optional: store chunk text

---

## ‚úÖ Confirmed Schema Details

Verified actual Notion schema:
- `Methods` = **rich_text** ‚úÖ (we're using this correctly)
- `Summary` = **rich_text** ‚úÖ (we're using this correctly)
- `Results` = **rich_text** ‚úÖ (we're using this correctly)
- `Conclusions` = **rich_text** ‚úÖ (need to add this)

---

## üéØ Next Steps for Cursor

To fully match ChatGPT's specification, Cursor needs to:

1. **Enhance `_extract_metadata_from_mwtab()`** to extract/derive:
   - `conclusions` (can use LLM or leave empty for now)
   - `data_origin` (infer: "External ‚Äì Open Dataset" for MW studies)
   - `dataset_source_type` (infer: "Processed table" if MS_METABOLITE_DATA present)
   - `source_url` (from mwTab METABOLOMICS WORKBENCH section or pass as param)

2. **Enhance `_update_experimental_data_asset_metadata()`** to set:
   - `Conclusions` (rich_text)
   - `Data Origin` (select)
   - `Dataset Source Type` (select)
   - `Source URL / DOI` (url)
   - Optionally: `Full Text (hidden)` and `Chunks (hidden)`

3. **Optional LLM Enhancement**: Consider using LLM to generate better `conclusions` and enhance `results` summaries.

---

## üìù Current Implementation Status

**Summary**: We have ~75% of the required functionality implemented. The core pipeline works, but we're missing:
- Conclusions field
- Data Origin / Dataset Source Type / Source URL
- Optional Full Text / Chunks fields

The foundation is solid and follows the exact patterns you requested. We just need to add the remaining fields.

---

## ‚úÖ Verification

To verify the current implementation works:
```bash
python scripts/ingest_dataset.py --dataset-page-id "2bdadf61-42ab-811c-b2b2-cbd014210210" --force
```

This will:
- ‚úÖ Embed to Pinecone
- ‚úÖ Set Embedding IDs + Last Embedded
- ‚úÖ Set Model Systems, Disease, Matrix, Methods, Summary, Results
- ‚ùå Missing: Conclusions, Data Origin, Dataset Source Type, Source URL

